apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: fluentd
  namespace: default
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    namespace: default
    server: 'https://kubernetes.default.svc'
  source:
    chart: fluentd
    repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 5.8.2
    helm:
      values: |
        aggregator:
          configMap: "elasticsearch-output"
          extraEnvVars:
            - name: ELASTICSEARCH_HOST
              value: "elasticsearch.default.svc.cluster.local"
            - name: ELASTICSEARCH_PORT
              value: "9200"
        forwarder:
          configMapFiles:
            fluentd.conf: |
              <match fluent.**>
                @type null
              </match>
              @include filters.conf
              @include fluentd-output.conf
              @include sources.conf
              @include fluentd-inputs.conf
            fluentd-inputs.conf: |
              {{- if .Values.aggregator.port }}
              <source>
                @type forward
                bind 0.0.0.0
                port {{ .Values.aggregator.port }}
                {{- if .Values.tls.enabled }}
                <transport tls>
                  ca_path /opt/bitnami/fluentd/certs/in_forward/ca.crt
                  cert_path /opt/bitnami/fluentd/certs/in_forward/tls.crt
                  private_key_path /opt/bitnami/fluentd/certs/in_forward/tls.key
                  client_cert_auth true
                </transport>
                {{- end }}
              </source>
              {{- end }}
              <source>
                @type http
                bind 0.0.0.0
                port 9880
              </source>
            sources.conf: |-
              <source>
                @id fluentd-containers.log
                @type tail
                path /var/log/containers/*.log
                pos_file /var/log/containers.log.pos
                tag raw.kubernetes.*
                read_from_head true
                <parse>
                  @type multi_format
                  <pattern>
                    format json
                    time_key time
                    time_format %Y-%m-%dT%H:%M:%S.%NZ
                  </pattern>
                  <pattern>
                    format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
                    time_format %Y-%m-%dT%H:%M:%S.%N%:z
                  </pattern>
                </parse>
              </source>
            filters.conf: |-
              <match raw.kubernetes.**>
                @id raw.kubernetes
                @type detect_exceptions
                remove_tag_prefix raw
                message log
                stream stream
                multiline_flush_interval 5
                max_bytes 500000
                max_lines 1000
              </match>
              <filter **>
                @id filter_concat
                @type concat
                key message
                multiline_end_regexp /\n$/
                separator ""
                timeout_label @NORMAL
                flush_interval 5
              </filter>
              <filter kubernetes.**>
                @id filter_kubernetes_metadata
                @type kubernetes_metadata
              </filter>
              <filter kubernetes.**>
                @id filter_parser
                @type parser
                key_name log
                reserve_time true
                reserve_data true
                remove_key_name_field true
                <parse>
                  @type multi_format
                  <pattern>
                    format json
                  </pattern>
                  <pattern>
                    format none
                  </pattern>
                </parse>
              </filter>
            # dispatch.conf: |-
            outputs.conf: |-
              <match **>
                @type relabel
                @label @NORMAL
              </match>
              <label @NORMAL>
              <match **>
                @id elasticsearch
                @type elasticsearch
                @log_level info
                include_tag_key true
                host "elasticsearch-master-hl"
                port 9200
                path ""
                scheme http
                ssl_verify true
                ssl_version TLSv1_2
                type_name _doc
                logstash_format true
                logstash_prefix logstash
                reconnect_on_error true
                <buffer>
                  @type file
                  path /var/log/fluentd-buffers/kubernetes.system.buffer
                  flush_mode interval
                  retry_type exponential_backoff
                  flush_thread_count 2
                  flush_interval 5s
                  retry_forever
                  retry_max_interval 30
                  chunk_limit_size 2M
                  queue_limit_length 8
                  overflow_action block
                </buffer>
              </match>
              </label>
  project: default
  syncPolicy:
    automated:
      prune: true
      selfHeal: true